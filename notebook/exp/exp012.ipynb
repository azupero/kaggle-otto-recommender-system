{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948880f8-7e07-4caa-b1c5-ab7120694b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import gc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "import polars as pl\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import hashlib\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import cupy as cp\n",
    "\n",
    "cudf.set_option(\"default_integer_bitwidth\", 32)\n",
    "cudf.set_option(\"default_float_bitwidth\", 32)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d471b8-ae41-4048-8766-3991f6ceac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    EXP_ID = \"012\"\n",
    "    VALIDATION = True\n",
    "    INPUT_DIR = Path(\"../../input/train_valid\") if VALIDATION else Path(\"../../input\")\n",
    "    OUTPUT_DIR = Path(f\"../../output/exp{EXP_ID}\")\n",
    "    CANDIDATE_FEATURE_DIR = OUTPUT_DIR / \"cv_candidate_feature\" if VALIDATION else OUTPUT_DIR / \"candidate_feature\"\n",
    "    RERANKING_FEATURE_DIR = OUTPUT_DIR / \"cv_reranking_feature\" if VALIDATION else OUTPUT_DIR / \"reranking_feature\"\n",
    "    DISK_PIECES = 4\n",
    "\n",
    "\n",
    "Path.mkdir(Config.OUTPUT_DIR, exist_ok=True)\n",
    "Path.mkdir(Config.CANDIDATE_FEATURE_DIR, exist_ok=True)\n",
    "Path.mkdir(Config.RERANKING_FEATURE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d7f899-fdcc-48e3-8b49-c37ce86159bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Utils\n",
    "# =================================\n",
    "def get_input_data(input_dir: Path, phase: str):\n",
    "    type_labels = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "    \n",
    "    dfs = []\n",
    "    for path in sorted(list(input_dir.glob(f\"{phase}_parquet/*.parquet\"))):\n",
    "        chunk = cudf.read_parquet(path)\n",
    "        chunk[\"session\"] = chunk[\"session\"].astype(\"int32\")\n",
    "        chunk[\"aid\"] = chunk[\"aid\"].astype(\"int32\")\n",
    "        chunk[\"ts\"] = (chunk[\"ts\"] / 1000).astype(\"int32\")\n",
    "        chunk[\"type\"] = chunk[\"type\"].map(type_labels).astype(\"int8\")\n",
    "        dfs.append(chunk)\n",
    "        \n",
    "    del chunk\n",
    "    gc.collect()\n",
    "    \n",
    "    return cudf.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def get_pl_input_data(input_dir: Path, phase: str):\n",
    "    type_labels = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "    \n",
    "    dfs = []\n",
    "    for path in sorted(list(input_dir.glob(f\"{phase}_parquet/*.parquet\"))):\n",
    "        chunk = pl.read_parquet(path)\n",
    "        chunk = chunk.with_columns([\n",
    "            pl.col(\"session\").cast(pl.Int32),\n",
    "            pl.col(\"aid\").cast(pl.Int32),\n",
    "            (pl.col(\"ts\") / 1000).cast(pl.Int32),\n",
    "            pl.col(\"type\").apply(lambda x: type_labels[x]).cast(pl.Int32)\n",
    "        ])\n",
    "        dfs.append(chunk)\n",
    "    \n",
    "    return pl.concat(dfs)\n",
    "\n",
    "\n",
    "def get_gpu_memory(cmd_path=\"nvidia-smi\",\n",
    "                   target_properties=(\"memory.total\", \"memory.used\")):\n",
    "    \"\"\"\n",
    "    ref: https://www.12-technology.com/2022/01/pythongpu.html\n",
    "    Returns\n",
    "    -------\n",
    "    gpu_total : ndarray,  \"memory.total\"\n",
    "    gpu_used: ndarray, \"memory.used\"\n",
    "    \"\"\"\n",
    "\n",
    "    # format option\n",
    "    format_option = \"--format=csv,noheader,nounits\"\n",
    "\n",
    "    cmd = '%s --query-gpu=%s %s' % (cmd_path, ','.join(target_properties), format_option)\n",
    "\n",
    "    # Command execution in sub-processes\n",
    "    cmd_res = subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    gpu_lines = cmd_res.decode().split('\\n')[0].split(', ')\n",
    "\n",
    "    gpu_total = int(gpu_lines[0]) / 1024\n",
    "    gpu_used = int(gpu_lines[1]) / 1024\n",
    "\n",
    "    gpu_total = np.round(gpu_used, 1)\n",
    "    gpu_used = np.round(gpu_used, 1)\n",
    "    return gpu_total, gpu_used\n",
    "\n",
    "\n",
    "class Trace():\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    @contextmanager\n",
    "    def timer(self, title):\n",
    "        t0 = time.time()\n",
    "        p = psutil.Process(os.getpid())\n",
    "        cpu_m0 = p.memory_info().rss / 2. ** 30\n",
    "        if self.cuda: gpu_m0 = get_gpu_memory()[0]\n",
    "        yield\n",
    "        cpu_m1 = p.memory_info().rss / 2. ** 30\n",
    "        if self.cuda: gpu_m1 = get_gpu_memory()[0]\n",
    "\n",
    "        cpu_delta = cpu_m1 - cpu_m0\n",
    "        if self.cuda: gpu_delta = gpu_m1 - gpu_m0\n",
    "\n",
    "        cpu_sign = '+' if cpu_delta >= 0 else '-'\n",
    "        cpu_delta = math.fabs(cpu_delta)\n",
    "\n",
    "        if self.cuda: gpu_sign = '+' if gpu_delta >= 0 else '-'\n",
    "        if self.cuda: gpu_delta = math.fabs(gpu_delta)\n",
    "\n",
    "        cpu_message = f'{cpu_m1:.1f}GB({cpu_sign}{cpu_delta:.1f}GB)'\n",
    "        if self.cuda: gpu_message = f'{gpu_m1:.1f}GB({gpu_sign}{gpu_delta:.1f}GB)'\n",
    "\n",
    "        if self.cuda:\n",
    "            message = f\"[cpu: {cpu_message}, gpu: {gpu_message}: {time.time() - t0:.1f}sec] {title} \"\n",
    "        else:\n",
    "            message = f\"[cpu: {cpu_message}: {time.time() - t0:.1f}sec] {title} \"\n",
    "\n",
    "        print(message, file=sys.stderr)\n",
    "        \n",
    "trace = Trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49523d66-107d-485c-baff-bf96e19c1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Candidate features\n",
    "# =================================\n",
    "def read_file(f):\n",
    "    type_labels = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "    df = cudf.read_parquet(f)\n",
    "    df[\"session\"] = df[\"session\"].astype(\"int32\")\n",
    "    df[\"aid\"] = df[\"aid\"].astype(\"int32\")\n",
    "    df[\"ts\"] = (df[\"ts\"] / 1000).astype(\"int32\")\n",
    "    df[\"type\"] = df[\"type\"].map(type_labels).astype(\"int8\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_type_weighted_co_visitation_matrix():\n",
    "    files = sorted(list(Config.INPUT_DIR.glob(\"*_parquet/*.parquet\"))) # test set leakを使う\n",
    "    CHUNK = int(np.ceil(len(files)/6))\n",
    "    READ_CT = 5\n",
    "    # ref: https://www.kaggle.com/code/cdeotte/compute-validation-score-cv-565\n",
    "    type_weight = {0: 1, 1: 6, 2: 3}\n",
    "    # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "    # OOM回避のため共起行列を分割して計算・保存\n",
    "    DISK_PIECES = 4\n",
    "    SIZE = 1.86e6 / DISK_PIECES\n",
    "    # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "    for part in range(DISK_PIECES):\n",
    "        print('### DISK PART', part+1)\n",
    "        \n",
    "        # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "        # 共起行列を2層のチャンクで計算\n",
    "        # => OUTER CHUNKS\n",
    "        for j in range(6):\n",
    "            a = j * CHUNK\n",
    "            b = min((j+1) * CHUNK, len(files))\n",
    "            print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "            \n",
    "            # => INNER CHUNKS\n",
    "            # CHUNKを更に分割して計算\n",
    "            for k in range(a, b, READ_CT):\n",
    "                # READ FILE\n",
    "                dfs = [read_file(files[k])]\n",
    "                for i in range(1, READ_CT):\n",
    "                    if k+i < b:\n",
    "                        dfs.append(read_file(files[k+i]))\n",
    "                \n",
    "                df = cudf.concat(dfs, ignore_index=True, axis=0)\n",
    "                df = df.sort_values(by=[\"session\", \"ts\"], ascending=[True, False]) # cumcountで最新30行を抽出するためにsessionを降順にしている\n",
    "                # USE TAIL OF SESSION\n",
    "                df = df.reset_index(drop=True)\n",
    "                df[\"n\"] = df.groupby(\"session\").cumcount()\n",
    "                df = df.loc[df[\"n\"] < 30].drop(\"n\",axis=1)\n",
    "                # CREATE PAIRS\n",
    "                df = df.merge(df, on=\"session\")\n",
    "                df = df.loc[((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n",
    "                # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "                df = df.loc[(df.aid_x >= part * SIZE) & (df.aid_x < (part+1) * SIZE)]\n",
    "                # ASSIGN WEIGHTS\n",
    "                df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', \"type_y\"])\n",
    "                df['wgt'] = df.type_y.map(type_weight)\n",
    "                df = df[['aid_x','aid_y','wgt']]\n",
    "                df.wgt = df.wgt.astype('float32')\n",
    "                df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "                # COMBINE INNER CHUNKS\n",
    "                if k==a:\n",
    "                    tmp2 = df\n",
    "                else:\n",
    "                    tmp2 = tmp2.add(df, fill_value=0)\n",
    "                    \n",
    "             # COMBINE OUTER CHUNKS\n",
    "            if a==0:\n",
    "                tmp = tmp2\n",
    "            else:\n",
    "                tmp = tmp.add(tmp2, fill_value=0)\n",
    "            \n",
    "            del tmp2, df\n",
    "            gc.collect()\n",
    "\n",
    "        # CONVERT MATRIX TO DICTIONARY\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = tmp.sort_values([\"aid_x\", \"wgt\"], ascending=[True, False])\n",
    "        # SAVE TOP 15\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        tmp[\"n\"] = tmp.groupby(\"aid_x\").aid_y.cumcount()\n",
    "        tmp = tmp.loc[tmp[\"n\"] < 15].drop(\"n\", axis=1)\n",
    "        # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "        tmp.to_pandas().to_parquet(Config.CANDIDATE_FEATURE_DIR / f\"top_15_carts_orders_{part}.pqt\")\n",
    "        \n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "def get_buy2buy_co_visitation_matrix():\n",
    "    files = sorted(list(Config.INPUT_DIR.glob(\"*_parquet/*.parquet\"))) # test set leakを使う\n",
    "    CHUNK = int(np.ceil(len(files)/6))\n",
    "    READ_CT = 5\n",
    "    # ref: https://www.kaggle.com/code/cdeotte/compute-validation-score-cv-565\n",
    "    # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "    # OOM回避のため共起行列を分割して計算・保存\n",
    "    DISK_PIECES = 1\n",
    "    SIZE = 1.86e6 / DISK_PIECES\n",
    "    # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "    for part in range(DISK_PIECES):\n",
    "        print('### DISK PART', part+1)\n",
    "        \n",
    "        # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "        # 共起行列を2層のチャンクで計算\n",
    "        # => OUTER CHUNKS\n",
    "        for j in range(6):\n",
    "            a = j * CHUNK\n",
    "            b = min((j+1) * CHUNK, len(files))\n",
    "            print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "            \n",
    "            # => INNER CHUNKS\n",
    "            # CHUNKを更に分割して計算\n",
    "            for k in range(a, b, READ_CT):\n",
    "                # READ FILE\n",
    "                dfs = [read_file(files[k])]\n",
    "                for i in range(1, READ_CT):\n",
    "                    if k+i < b:\n",
    "                        dfs.append(read_file(files[k+i]))\n",
    "                \n",
    "                df = cudf.concat(dfs, ignore_index=True, axis=0)\n",
    "                df = df.loc[df[\"type\"].isin([1, 2])] # ONLY WANT CARTS AND ORDERS\n",
    "                df = df.sort_values(by=[\"session\", \"ts\"], ascending=[True, False]) # cumcountで最新30行を抽出するためにsessionを降順にしている\n",
    "                # USE TAIL OF SESSION\n",
    "                df = df.reset_index(drop=True)\n",
    "                df['n'] = df.groupby('session').cumcount()\n",
    "                df = df.loc[df.n<30].drop('n',axis=1)\n",
    "                # CREATE PAIRS\n",
    "                df = df.merge(df, on='session')\n",
    "                df = df.loc[((df.ts_x - df.ts_y).abs() < 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y)] # 14days\n",
    "                # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "                df = df.loc[(df.aid_x >= part*SIZE) & (df.aid_x < (part+1)*SIZE)]\n",
    "                # ASSIGN WEIGHTS\n",
    "                df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', \"type_y\"])\n",
    "                df['wgt'] = 1\n",
    "                df = df[['aid_x','aid_y','wgt']]\n",
    "                df.wgt = df.wgt.astype('float32')\n",
    "                df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "                # COMBINE INNER CHUNKS\n",
    "                if k==a:\n",
    "                    tmp2 = df\n",
    "                else:\n",
    "                    tmp2 = tmp2.add(df, fill_value=0)\n",
    "                    \n",
    "             # COMBINE OUTER CHUNKS\n",
    "            if a==0:\n",
    "                tmp = tmp2\n",
    "            else:\n",
    "                tmp = tmp.add(tmp2, fill_value=0)\n",
    "            \n",
    "            del tmp2, df\n",
    "            gc.collect()\n",
    "\n",
    "        # CONVERT MATRIX TO DICTIONARY\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "        # SAVE TOP 15\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "        tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "        # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "        tmp.to_pandas().to_parquet(Config.CANDIDATE_FEATURE_DIR / f\"top_15_buy2buy_{part}.pqt\")\n",
    "        \n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "def get_clicks_co_visitation_matrix():\n",
    "    files = sorted(list(Config.INPUT_DIR.glob(\"*_parquet/*.parquet\"))) # test set leakを使う\n",
    "    CHUNK = int(np.ceil(len(files)/6))\n",
    "    READ_CT = 5\n",
    "    # ref: https://www.kaggle.com/code/cdeotte/compute-validation-score-cv-565\n",
    "    # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "    # OOM回避のため共起行列を分割して計算・保存\n",
    "    DISK_PIECES = 4\n",
    "    SIZE = 1.86e6 / DISK_PIECES\n",
    "    # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "    for part in range(DISK_PIECES):\n",
    "        print('### DISK PART', part+1)\n",
    "        \n",
    "        # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "        # 共起行列を2層のチャンクで計算\n",
    "        # => OUTER CHUNKS\n",
    "        for j in range(6):\n",
    "            a = j * CHUNK\n",
    "            b = min((j+1) * CHUNK, len(files))\n",
    "            print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "            \n",
    "            # => INNER CHUNKS\n",
    "            # CHUNKを更に分割して計算\n",
    "            for k in range(a, b, READ_CT):\n",
    "                # READ FILE\n",
    "                dfs = [read_file(files[k])]\n",
    "                for i in range(1, READ_CT):\n",
    "                    if k+i < b:\n",
    "                        dfs.append(read_file(files[k+i]))\n",
    "                \n",
    "                df = cudf.concat(dfs, ignore_index=True, axis=0)\n",
    "                df = df.sort_values(by=[\"session\", \"ts\"], ascending=[True, False]) # cumcountで最新30行を抽出するためにsessionを降順にしている\n",
    "                # USE TAIL OF SESSION\n",
    "                df = df.reset_index(drop=True)\n",
    "                df['n'] = df.groupby('session').cumcount()\n",
    "                df = df.loc[df.n<30].drop('n',axis=1)\n",
    "                # CREATE PAIRS\n",
    "                df = df.merge(df, on='session')\n",
    "                df = df.loc[((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n",
    "                # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "                df = df.loc[(df.aid_x >= part*SIZE) & (df.aid_x < (part+1)*SIZE)]\n",
    "                # ASSIGN WEIGHTS\n",
    "                df = df[['session', \"ts_x\", 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', \"type_y\"])\n",
    "                df[\"wgt\"] = 1 + 3 * (df[\"ts_x\"] - 1659304800) / (1662328791 - 1659304800)\n",
    "                df = df[['aid_x','aid_y','wgt']]\n",
    "                df.wgt = df.wgt.astype('float32')\n",
    "                df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "                # COMBINE INNER CHUNKS\n",
    "                if k==a:\n",
    "                    tmp2 = df\n",
    "                else:\n",
    "                    tmp2 = tmp2.add(df, fill_value=0)\n",
    "                    \n",
    "             # COMBINE OUTER CHUNKS\n",
    "            if a==0:\n",
    "                tmp = tmp2\n",
    "            else:\n",
    "                tmp = tmp.add(tmp2, fill_value=0)\n",
    "            \n",
    "            del tmp2, df\n",
    "            gc.collect()\n",
    "\n",
    "        # CONVERT MATRIX TO DICTIONARY\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "        # SAVE TOP 15\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "        tmp = tmp.loc[tmp[\"n\"] < 20].drop('n',axis=1)\n",
    "        # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "        tmp.to_pandas().to_parquet(Config.CANDIDATE_FEATURE_DIR / f\"top_20_clicks_{part}.pqt\")\n",
    "        \n",
    "    del tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762edc17-3c35-4c18-b9d9-a80ecd7be1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"load all data\"):\n",
    "    train_df = get_pl_input_data(Config.INPUT_DIR, \"train\")\n",
    "    test_df = get_pl_input_data(Config.INPUT_DIR, \"test\")\n",
    "    whole_df = pl.concat([train_df, test_df])\n",
    "    # whole_df = whole_df.with_column((pl.col(\"aid\").cast(str) + \"_\" +  pl.col(\"type\").cast(str)).alias(\"aid_type\"))\n",
    "    \n",
    "    del train_df, test_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd9b93-3624-4dd7-803d-f8108d6f7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfxn(x):\n",
    "    return int(hashlib.md5(str(x).encode()).hexdigest(), 16)\n",
    "\n",
    "\n",
    "def get_item2vec(input_df: pl.DataFrame, type_label: int):\n",
    "    corpus = input_df.filter(pl.col(\"type\") == type_label).groupby([\"session\"]).agg(pl.col(\"aid\"))[\"aid\"].to_list()\n",
    "    item2vec = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=100,\n",
    "        window=20,\n",
    "        min_count=1,\n",
    "        sg=1,\n",
    "        hs=0,\n",
    "        hashfxn=hashfxn,\n",
    "        epochs=300,\n",
    "        seed=42,\n",
    "        workers=-1\n",
    "    )\n",
    "    item2vec.wv.save(str(Config.CANDIDATE_FEATURE_DIR / f\"item2vec_{type_label}.wordvectors\"))\n",
    "    \n",
    "    del corpus, item2vec\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# def get_item2vec(input_df: pl.DataFrame):\n",
    "#     corpus = input_df.groupby([\"session\"]).agg(pl.col(\"aid_type\"))[\"aid_type\"].to_list()\n",
    "#     item2vec = Word2Vec(\n",
    "#         sentences=corpus,\n",
    "#         vector_size=100,\n",
    "#         window=20,\n",
    "#         min_count=1,\n",
    "#         sg=1,\n",
    "#         hs=0,\n",
    "#         hashfxn=hashfxn,\n",
    "#         epochs=100,\n",
    "#         seed=42,\n",
    "#         workers=-1\n",
    "#     )\n",
    "#     item2vec.wv.save(str(Config.CANDIDATE_FEATURE_DIR / f\"item2vec.wordvectors\"))\n",
    "    \n",
    "#     del corpus, item2vec\n",
    "#     gc.collect()\n",
    "    \n",
    "    \n",
    "# with trace.timer(\"item2vec\"):\n",
    "#     get_item2vec(whole_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76be2b-35d6-446d-90bd-4f92d7b235c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with trace.timer(\"clicks item2vec\"):\n",
    "    get_item2vec(whole_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ab54b-c22e-4aac-b52d-1e7bf6b879f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"carts item2vec\"):\n",
    "    get_item2vec(whole_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df946fa-8d4b-4ba2-887a-2104fba17ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"orders item2vec\"):\n",
    "    get_item2vec(whole_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c749e-b31e-4921-a5c6-478218bd14de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with trace.timer(\"cart_co_matirx\"):\n",
    "    get_type_weighted_co_visitation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736689c-9515-43ed-8106-cb56bd292d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"buy2buy_co_matirx\"):\n",
    "    get_buy2buy_co_visitation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced086d-c1c8-49fa-a9c3-37f41c784b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"clicks_co_matirx\"):\n",
    "    get_clicks_co_visitation_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103e4ce-69de-4785-8630-8a8461e71823",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05bf36a-8467-4cee-9ff2-b5007a8ad83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "\n",
    "def parquet2dict(path: Path) -> dict:\n",
    "    df = pd.read_parquet(path)\n",
    "    return df.groupby([\"aid_x\"])[\"aid_y\"].apply(list).to_dict()\n",
    "    # return df.groupby([\"aid_x\"]).parallel_apply(lambda x: x[\"aid_y\"].to_list()).to_dict()\n",
    "\n",
    "    \n",
    "def suggest_clicks(df):\n",
    "    # USE USER HISTORY AIDS AND TYPES\n",
    "    aids = df[\"aid\"].to_list()\n",
    "    types = df[\"type\"].to_list()\n",
    "    # UNIQUE AIDS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids) >= 20:\n",
    "        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter()\n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        \n",
    "        return sorted_aids\n",
    "    \n",
    "    # USE \"CLICKS\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid for aid, cnt in Counter(aids2).most_common(20) if aid not in unique_aids]    \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    \n",
    "    # USE TOP20 TEST CLICKS\n",
    "    aids4 = [aid for aid in list(top_clicks) if aid not in result]\n",
    "    return result + aids4[:20 - len(result)]\n",
    "\n",
    "\n",
    "def suggest_carts(df):\n",
    "    # USE USER HISTORY AIDS AND TYPES\n",
    "    aids = df[\"aid\"].to_list()\n",
    "    types = df[\"type\"].to_list()\n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "    df = df.loc[(df['type']==0) | (df['type']==1)]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids) >= 20:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "        aids3 = list(itertools.chain(*[top_15_carts2orders[aid] for aid in unique_buys if aid in top_15_carts2orders]))\n",
    "        for aid in aids3:\n",
    "            aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        \n",
    "        return sorted_aids\n",
    "    \n",
    "    # USE \"CART ORDER\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "    aids3 = list(itertools.chain(*[top_15_carts2orders[aid] for aid in unique_buys if aid in top_15_carts2orders]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2 + aids3).most_common(20) if aid2 not in unique_aids] \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    \n",
    "    # USE TOP20 TEST ORDERS\n",
    "    aids4 = [aid for aid in list(top_carts) if aid not in result]\n",
    "    return result + aids4[:20 - len(result)]\n",
    "\n",
    "\n",
    "def suggest_buys(df):\n",
    "    # USE USER HISTORY AIDS AND TYPES\n",
    "    aids = df[\"aid\"].to_list()\n",
    "    types = df[\"type\"].to_list()\n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "    df = df.loc[(df['type']==1) | (df['type']==2)]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids) >= 20:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "        aids3 = list(itertools.chain(*[top_15_buy2buy[aid] for aid in unique_buys if aid in top_15_buy2buy]))\n",
    "        for aid in aids3:\n",
    "            aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        \n",
    "        return sorted_aids\n",
    "    \n",
    "    # USE \"CART ORDER\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_15_carts2orders[aid] for aid in unique_aids if aid in top_15_carts2orders]))\n",
    "    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "    aids3 = list(itertools.chain(*[top_15_buy2buy[aid] for aid in unique_buys if aid in top_15_buy2buy]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2 + aids3).most_common(20) if aid2 not in unique_aids] \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    \n",
    "    # USE TOP20 TEST ORDERS\n",
    "    aids4 = [aid for aid in list(top_orders) if aid not in result]\n",
    "    return result + aids4[:20 - len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e48022e-41da-439d-8ad0-2b603e35ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "# N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "# def df_parallelize_run(func, t_split):\n",
    "    \n",
    "#     num_cores = np.min([N_CORES, len(t_split)])\n",
    "#     pool = Pool(num_cores)\n",
    "#     df = pool.map(func, t_split)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "# def suggest_clicks(df):\n",
    "#     # USE USER HISTORY AIDS AND TYPES\n",
    "#     aids = df[\"aid\"].to_list()\n",
    "#     types = df[\"type\"].to_list()\n",
    "#     session = df[\"session\"].unique()[0]\n",
    "#     # UNIQUE AIDS\n",
    "#     unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     # df = df.loc[(df['type']==0)]\n",
    "#     # unique_clicks = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "#     # # USE USER HISTORY AIDS AND TYPES\n",
    "#     # session = df[0]\n",
    "#     # aids = df[1]\n",
    "#     # types = df[2]\n",
    "#     # # UNIQUE AIDS\n",
    "#     # unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     # unique_clicks = list(dict.fromkeys([f for i, f in enumerate(aids) if types[i] in [0]][::-1]))\n",
    "    \n",
    "#     # RERANK CANDIDATES USING WEIGHTS\n",
    "#     if len(unique_aids) >= 20:\n",
    "#         weights = np.logspace(0.1, 1, len(aids),base=2, endpoint=True) - 1\n",
    "#         aids_temp = Counter()\n",
    "#         # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "#         for aid, w, t in zip(aids, weights, types): \n",
    "#             aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "#         sorted_aids = [k for k, v in aids_temp.most_common(20)]\n",
    "        \n",
    "#         return sorted_aids\n",
    "    \n",
    "#     if session in click_session2index:\n",
    "#         # USE item2vec\n",
    "#         aids2 = index2key[click_indices[click_session2index[session]]]\n",
    "#         # aids2 = list(aids2)\n",
    "#         aids2 = [aid.split(\"_\")[0] for aid in aids2 if int(aid.split(\"_\")[1]) in [0, 1, 2]]\n",
    "#         # RERANK CANDIDATES\n",
    "#         top_aids2 = [aid2 for aid2 in aids2 if aid2 not in unique_aids]    \n",
    "#         result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "#     else:\n",
    "#         result = []\n",
    "    \n",
    "#     # USE TOP20 TEST CLICKS\n",
    "#     return result + list(top_clicks)[:20 - len(result)]\n",
    "\n",
    "\n",
    "# def suggest_carts(df):\n",
    "#     # USE USER HISTORY AIDS AND TYPES\n",
    "#     aids = df[\"aid\"].to_list()\n",
    "#     types = df[\"type\"].to_list()\n",
    "#     session = df[\"session\"].unique()[0]\n",
    "#     # UNIQUE AIDS\n",
    "#     unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     df = df.loc[(df['type'] == 0) | (df['type'] == 1)]\n",
    "#     unique_carts = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "#     # # USE USER HISTORY AIDS AND TYPES\n",
    "#     # session = df[0]\n",
    "#     # aids = df[1]\n",
    "#     # types = df[2]\n",
    "#     # # UNIQUE AIDS\n",
    "#     # unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     # unique_carts = list(dict.fromkeys([f for i, f in enumerate(aids) if types[i] in [1]][::-1]))\n",
    "#     # RERANK CANDIDATES USING WEIGHTS\n",
    "#     if len(unique_aids) >= 20:\n",
    "#         weights = np.logspace(0.1, 1, len(aids),base=2, endpoint=True) - 1\n",
    "#         aids_temp = Counter()\n",
    "#         # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "#         for aid, w, t in zip(aids, weights, types): \n",
    "#             aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "#         sorted_aids = [k for k, v in aids_temp.most_common(20)]\n",
    "        \n",
    "#         return sorted_aids\n",
    "    \n",
    "#     if session in cart_session2index:\n",
    "#         # USE item2vec\n",
    "#         aids2 = index2key[cart_indices[cart_session2index[session]]]\n",
    "#         # aids2 = list(aids2)\n",
    "#         aids2 = [aid.split(\"_\")[0] for aid in aids2 if int(aid.split(\"_\")[1]) in [0, 1]]\n",
    "#         # RERANK CANDIDATES\n",
    "#         top_aids2 = [aid2 for aid2 in aids2 if aid2 not in unique_carts]    \n",
    "#         result = unique_carts + top_aids2[:20 - len(unique_carts)]\n",
    "#     else:\n",
    "#         result = []\n",
    "    \n",
    "#     # USE TOP20 TEST CLICKS\n",
    "#     return result + list(top_carts)[:20 - len(result)]\n",
    "\n",
    "\n",
    "# def suggest_orders(df):\n",
    "#     # USE USER HISTORY AIDS AND TYPES\n",
    "#     aids = df[\"aid\"].to_list()\n",
    "#     types = df[\"type\"].to_list()\n",
    "#     session = df[\"session\"].unique()[0]\n",
    "#     # UNIQUE AIDS\n",
    "#     unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     df = df.loc[(df['type'] == 1) | (df['type'] == 2)]\n",
    "#     unique_orders = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "#     # # USE USER HISTORY AIDS AND TYPES\n",
    "#     # session = df[0]\n",
    "#     # aids = df[1]\n",
    "#     # types = df[2]\n",
    "#     # # UNIQUE AIDS\n",
    "#     # unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "#     # unique_orders = list(dict.fromkeys([f for i, f in enumerate(aids) if types[i] in [2]][::-1]))\n",
    "#     # RERANK CANDIDATES USING WEIGHTS\n",
    "#     if len(unique_aids) >= 20:\n",
    "#         weights = np.logspace(0.1, 1, len(aids),base=2, endpoint=True) - 1\n",
    "#         aids_temp = Counter()\n",
    "#         # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "#         for aid, w, t in zip(aids, weights, types): \n",
    "#             aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "#         sorted_aids = [k for k, v in aids_temp.most_common(20)]\n",
    "        \n",
    "#         return sorted_aids\n",
    "    \n",
    "#     if session in order_session2index:\n",
    "#         # USE item2vec\n",
    "#         aids2 = index2key[order_indices[order_session2index[session]]]\n",
    "#         # aids2 = list(aids2)\n",
    "#         aids2 = [aid.split(\"_\")[0] for aid in aids2 if int(aid.split(\"_\")[1]) in [1, 2]]\n",
    "#         # RERANK CANDIDATES\n",
    "#         top_aids2 = [aid2 for aid2 in aids2 if aid2 not in unique_orders]    \n",
    "#         result = unique_orders + top_aids2[:20 - len(unique_orders)]\n",
    "#     else:\n",
    "#         result = []\n",
    "    \n",
    "#     # USE TOP20 TEST CLICKS\n",
    "#     return result + list(top_orders)[:20 - len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b77ccf-69ac-4956-ac97-61f2f46a4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_similar_items_by_item2vec(item2vec_model, session_type):\n",
    "#     input_df = get_input_data(Config.INPUT_DIR, \"test\")\n",
    "#     # last 30 events per session\n",
    "#     input_df = input_df.sort_values(by=[\"session\", \"ts\"], ascending=[True, False])\n",
    "#     input_df[\"n\"] = input_df.groupby([\"session\"]).cumcount()\n",
    "#     input_df = input_df.loc[input_df[\"n\"] < 30].reset_index(drop=True)\n",
    "#     # item2vecに含まれるaidにfintering\n",
    "#     input_df[\"aid_type\"] = input_df[\"aid\"].astype(str) + \"_\" + input_df[\"type\"].astype(str)\n",
    "#     input_df = input_df.loc[input_df[\"aid_type\"].isin(item2vec_model.index_to_key)].reset_index(drop=True)\n",
    "#     # input_df = input_df.loc[input_df[\"aid\"].isin(item2vec_model.index_to_key)].reset_index(drop=True)\n",
    "\n",
    "#     # sessionにtype == clickがないイベントログ\n",
    "#     input_df[\"is_type\"] = input_df[\"type\"].isin(session_type).astype(\"int8\")\n",
    "#     input_df[\"count_type\"] = input_df.groupby(\"session\")[\"is_type\"].transform(\"sum\")\n",
    "\n",
    "#     output_df = input_df.loc[(input_df[\"type\"].isin(session_type)) & (input_df[\"count_type\"] > 0)]\n",
    "#     output_df = cudf.concat([output_df, input_df.loc[input_df[\"count_type\"] == 0]], ignore_index=True)\n",
    "#     output_df = output_df.sort_values(by=[\"session\", \"ts\"]).reset_index(drop=True).drop(columns=[\"is_type\", \"count_type\"])\n",
    "    \n",
    "#     session_idx = np.cumsum(output_df.groupby([\"session\"], sort=True).size().to_numpy())\n",
    "#     session2index = {k: v for v, k in enumerate(sorted(output_df[\"session\"].unique().to_pandas().to_list()))}\n",
    "    \n",
    "#     # session embedding\n",
    "#     session_embeddings = item2vec_model[output_df[\"aid_type\"].to_numpy()]\n",
    "#     # session_embeddings = item2vec_model[output_df[\"aid\"].to_numpy()]\n",
    "#     session_embeddings = np.split(session_embeddings, session_idx[:-1])\n",
    "#     session_embeddings = np.array([np.mean(i, axis=0) for i in session_embeddings])\n",
    "    \n",
    "#     # most similars\n",
    "#     model = NearestNeighbors(n_neighbors=20, metric=\"cosine\", output_type=\"numpy\")\n",
    "#     model.fit(item2vec_model.vectors)\n",
    "    \n",
    "#     _, indices = model.kneighbors(session_embeddings)\n",
    "    \n",
    "#     del input_df, output_df, session_embeddings, model\n",
    "#     gc.collect()\n",
    "    \n",
    "#     return session2index, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14751a2d-686e-4e45-9319-16b4f02f9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_similar_items(word2vec):\n",
    "#     X = cp.array(word2vec.vectors)\n",
    "#     model = NearestNeighbors(n_neighbors=21, metric=\"cosine\", output_type=\"numpy\")\n",
    "#     model.fit(X)\n",
    "    \n",
    "#     _, indices = model.kneighbors(X)\n",
    "    \n",
    "#     del X, model\n",
    "#     gc.collect()\n",
    "    \n",
    "#     return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a991f4-a5b3-4123-a1d5-023d8ee88498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 6.7GB(+0.1GB), gpu: 1.3GB(+0.0GB): 3.0sec] load test set \n"
     ]
    }
   ],
   "source": [
    "with trace.timer(\"load test set\"):\n",
    "    test_df = get_input_data(Config.INPUT_DIR, \"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcea191f-d872-4a86-81cf-e14a339ca874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098530</td>\n",
       "      <td>409236</td>\n",
       "      <td>1661119369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58065</th>\n",
       "      <td>11108530</td>\n",
       "      <td>680375</td>\n",
       "      <td>1661128123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58066</th>\n",
       "      <td>11108530</td>\n",
       "      <td>108125</td>\n",
       "      <td>1661128171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067</th>\n",
       "      <td>11108531</td>\n",
       "      <td>952464</td>\n",
       "      <td>1661127918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58068</th>\n",
       "      <td>11108531</td>\n",
       "      <td>248689</td>\n",
       "      <td>1661280373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58069</th>\n",
       "      <td>11108532</td>\n",
       "      <td>610159</td>\n",
       "      <td>1661127918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58070 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session      aid          ts  type\n",
       "0      11098528    11830  1661119200     0\n",
       "1      11098529  1105029  1661119200     0\n",
       "2      11098530   264500  1661119200     0\n",
       "3      11098530   264500  1661119288     0\n",
       "4      11098530   409236  1661119369     0\n",
       "...         ...      ...         ...   ...\n",
       "58065  11108530   680375  1661128123     0\n",
       "58066  11108530   108125  1661128171     0\n",
       "58067  11108531   952464  1661127918     0\n",
       "58068  11108531   248689  1661280373     0\n",
       "58069  11108532   610159  1661127918     0\n",
       "\n",
       "[58070 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[test_df[\"session\"].isin(test_df[\"session\"].unique()[:10000])].reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7be783-02b8-46ee-8b42-64e1f9520998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 6.6GB(+3.6GB), gpu: 1.3GB(+0.0GB): 81.3sec] load candidate feature \n"
     ]
    }
   ],
   "source": [
    "with trace.timer(\"load candidate feature\"):\n",
    "    # type_weighted\n",
    "    top_15_carts2orders = parquet2dict(Config.CANDIDATE_FEATURE_DIR / \"top_15_carts_orders_0.pqt\")\n",
    "    for i in range(1, Config.DISK_PIECES):\n",
    "        top_15_carts2orders.update(parquet2dict(Config.CANDIDATE_FEATURE_DIR / f\"top_15_carts_orders_{i}.pqt\"))\n",
    "    \n",
    "    # buy2buy\n",
    "    top_15_buy2buy = parquet2dict(Config.CANDIDATE_FEATURE_DIR / \"top_15_buy2buy_0.pqt\")\n",
    "    \n",
    "    # clicks\n",
    "    top_20_clicks = parquet2dict(Config.CANDIDATE_FEATURE_DIR / \"top_20_clicks_0.pqt\")\n",
    "    for i in range(1, Config.DISK_PIECES):\n",
    "        top_20_clicks.update(parquet2dict(Config.CANDIDATE_FEATURE_DIR / f\"top_20_clicks_{i}.pqt\"))\n",
    "        \n",
    "    top_clicks = test_df.loc[test_df[\"type\"] == 0, \"aid\"].value_counts().index.to_numpy()[:20]\n",
    "    top_carts = test_df.loc[test_df[\"type\"] == 1, \"aid\"].value_counts().index.to_numpy()[:20]\n",
    "    top_orders = test_df.loc[test_df[\"type\"] == 2, \"aid\"].value_counts().index.to_numpy()[:20]\n",
    "    \n",
    "#     # clicks\n",
    "#     click_model = KeyedVectors.load(str(Config.CANDIDATE_FEATURE_DIR / \"item2vec_0.wordvectors\"), mmap=\"r\")\n",
    "#     click_index2key = np.array(click_model.index_to_key)\n",
    "#     click_indices = get_similar_items(click_model)\n",
    "    \n",
    "#     # carts\n",
    "#     cart_model = KeyedVectors.load(str(Config.CANDIDATE_FEATURE_DIR / \"item2vec_1.wordvectors\"), mmap=\"r\")\n",
    "#     cart_index2key = np.array(cart_model.index_to_key)\n",
    "#     cart_indices = get_similar_items(cart_model)\n",
    "    \n",
    "#     # orders\n",
    "#     order_model = KeyedVectors.load(str(Config.CANDIDATE_FEATURE_DIR / \"item2vec_2.wordvectors\"), mmap=\"r\")\n",
    "#     order_index2key = np.array(order_model.index_to_key)\n",
    "#     order_indices = get_similar_items(order_model)\n",
    "    \n",
    "    # all\n",
    "    # item2vec = KeyedVectors.load(str(Config.CANDIDATE_FEATURE_DIR / \"item2vec.wordvectors\"), mmap=\"r\")\n",
    "    # index2key = np.array(item2vec.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1aecb0-27b2-4c9e-bb72-c2bcaf9d2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with trace.timer(\"load test set\"):\n",
    "#     temp = [group for name, group in test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"])]\n",
    "#     test_list = [[i[\"session\"].iloc[0], i[\"aid\"].to_list(), i[\"type\"].to_list()] for i in temp]\n",
    "    \n",
    "#     del temp, test_df\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9caa3a8-1722-4130-ae06-ec786ff89385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 6.5GB(+0.0GB), gpu: 1.3GB(+0.0GB): 6.8sec] click inference \n"
     ]
    }
   ],
   "source": [
    "with trace.timer(\"click inference\"):\n",
    "    # click_session2index, click_indices = get_similar_items_by_item2vec(item2vec, [0, 1, 2])\n",
    "    # temp = df_parallelize_run(suggest_clicks, test_list)\n",
    "    # pred_clicks = pd.Series([f[1] for f in temp], index=[f[0] for f in temp])\n",
    "    pred_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(suggest_clicks)\n",
    "    # pred_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).parallel_apply(lambda x: suggest_clicks(x))\n",
    "    \n",
    "    #del click_session2index, click_indices, click_model, click_index2key #temp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1387c53-ac67-4250-804d-33dcab274a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 6.5GB(+0.0GB), gpu: 1.3GB(+0.0GB): 10.2sec] cart inference \n"
     ]
    }
   ],
   "source": [
    "with trace.timer(\"cart inference\"):\n",
    "    # cart_session2index, cart_indices = get_similar_items_by_item2vec(item2vec, [0, 1])\n",
    "    # temp = df_parallelize_run(suggest_carts, test_list)\n",
    "    # pred_carts = pd.Series([f[1] for f in temp], index=[f[0] for f in temp])\n",
    "    pred_carts = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(suggest_carts)\n",
    "    \n",
    "    #del cart_session2index, cart_indices, #cart_model, cart_index2key #temp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c353e33-659d-44f9-8425-38465ef6f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 6.5GB(+0.0GB), gpu: 1.3GB(+0.0GB): 9.4sec] order inference \n"
     ]
    }
   ],
   "source": [
    "with trace.timer(\"order inference\"):\n",
    "    # order_session2index, order_indices = get_similar_items_by_item2vec(item2vec, [1, 2])\n",
    "    # temp = df_parallelize_run(suggest_orders, test_list)\n",
    "    # pred_orders = pd.Series([f[1] for f in temp], index=[f[0] for f in temp])\n",
    "    pred_orders = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(suggest_buys)\n",
    "    \n",
    "    #del order_session2index, order_indices, #order_model, order_index2key #temp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "925c45ab-6559-461b-8b54-a6b18cf1c894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>588923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1732105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>571762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098528</td>\n",
       "      <td>884502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11108532</td>\n",
       "      <td>1758681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>11108532</td>\n",
       "      <td>1674003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11108532</td>\n",
       "      <td>356615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>11108532</td>\n",
       "      <td>507852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11108532</td>\n",
       "      <td>87613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session      aid\n",
       "0       11098528    11830\n",
       "1       11098528   588923\n",
       "2       11098528  1732105\n",
       "3       11098528   571762\n",
       "4       11098528   884502\n",
       "...          ...      ...\n",
       "199995  11108532  1758681\n",
       "199996  11108532  1674003\n",
       "199997  11108532   356615\n",
       "199998  11108532   507852\n",
       "199999  11108532    87613\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = cudf.from_pandas(test_df)\n",
    "\n",
    "candidate_df = cudf.from_pandas(pred_carts).explode().astype(\"int32\").reset_index(name=\"aid\")\n",
    "candidate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70d1d7-d24c-42da-9d33-20205a6565bb",
   "metadata": {},
   "source": [
    "### item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10443978-6e7a-429c-aad4-aba70ed960d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175797</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760273</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1369281</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2179603</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305872</th>\n",
       "      <td>855699</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305873</th>\n",
       "      <td>456376</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305874</th>\n",
       "      <td>471801</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305875</th>\n",
       "      <td>1390306</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305876</th>\n",
       "      <td>1369584</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2305877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aid  count\n",
       "0         175797     30\n",
       "1         326515      5\n",
       "2        1760273     23\n",
       "3        1369281      9\n",
       "4        2179603      2\n",
       "...          ...    ...\n",
       "2305872   855699      3\n",
       "2305873   456376      2\n",
       "2305874   471801      9\n",
       "2305875  1390306      5\n",
       "2305876  1369584     18\n",
       "\n",
       "[2305877 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_co_carts_orders_aggregates():\n",
    "    \"\"\"\n",
    "    item-based CFのカウント\n",
    "    \"\"\"\n",
    "    filepath = list(Config.CANDIDATE_FEATURE_DIR.glob(\"top_15_carts_orders_*.pqt\"))\n",
    "    for i, f in enumerate(filepath):\n",
    "        tmp = cudf.read_parquet(f)\n",
    "        \n",
    "        if i == 0:\n",
    "            df = tmp\n",
    "        else:\n",
    "            df = df.add(tmp, fill_value=0)\n",
    "    \n",
    "    # aggreagte\n",
    "    df = df.groupby([\"aid_y\"]).agg({\"aid_y\": [\"count\"]}).reset_index()\n",
    "    df.columns = [\"aid\", \"count\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "item_feature = get_co_carts_orders_aggregates()\n",
    "item_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c735ab3-46ee-40ef-9815-6f1781948f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>count</th>\n",
       "      <th>n_session</th>\n",
       "      <th>last_ts</th>\n",
       "      <th>count_click</th>\n",
       "      <th>count_cart</th>\n",
       "      <th>count_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661120947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661170019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1661180457</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1661142855</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661464855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30278</th>\n",
       "      <td>1855448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661608631</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>1855495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661374858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>1855500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1661125503</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>1855508</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1661185344</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>1855594</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1661119751</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30283 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aid  count  n_session     last_ts  count_click  count_cart  \\\n",
       "0            3      1          1  1661120947            1           0   \n",
       "1          219      1          1  1661170019            1           0   \n",
       "2          240      2          2  1661180457            2           0   \n",
       "3          247      4          2  1661142855            4           0   \n",
       "4          316      1          1  1661464855            1           0   \n",
       "...        ...    ...        ...         ...          ...         ...   \n",
       "30278  1855448      1          1  1661608631            1           0   \n",
       "30279  1855495      1          1  1661374858            1           0   \n",
       "30280  1855500      3          3  1661125503            3           0   \n",
       "30281  1855508      2          2  1661185344            1           1   \n",
       "30282  1855594      1          1  1661119751            1           0   \n",
       "\n",
       "       count_order  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "30278            0  \n",
       "30279            0  \n",
       "30280            0  \n",
       "30281            0  \n",
       "30282            0  \n",
       "\n",
       "[30283 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_aid_describe(input_df):\n",
    "    \"\"\"\n",
    "    各itemの過去実績\n",
    "    \"\"\"\n",
    "    feature = input_df.groupby([\"aid\"]).agg({\"aid\": \"count\", \"session\": \"nunique\", \"ts\": \"last\"})\n",
    "    feature.columns = [\"count\", \"n_session\", \"last_ts\"]\n",
    "    # count events each type\n",
    "    for i, name in enumerate([\"click\", \"cart\", \"order\"]):\n",
    "        tmp = input_df.loc[input_df[\"type\"] == i].groupby([\"aid\"]).agg({\"aid\": \"count\"})\n",
    "        tmp.columns = [f\"count_{name}\"]\n",
    "        \n",
    "        feature = cudf.concat([feature, tmp], axis=1)\n",
    "        \n",
    "        del tmp\n",
    "        gc.collect()\n",
    "        \n",
    "    return feature.fillna(0).reset_index()\n",
    "\n",
    "\n",
    "item_feature = get_aid_describe(test_df)\n",
    "item_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353816d-4864-47a2-94f4-b44cb38cf460",
   "metadata": {},
   "source": [
    "### session features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f9c3e59-0401-4e9c-b4e2-df27743615ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>count_event</th>\n",
       "      <th>count_aid</th>\n",
       "      <th>count_click</th>\n",
       "      <th>count_cart</th>\n",
       "      <th>count_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>11108528</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>11108529</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>11108530</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>11108531</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>11108532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session  count_event  count_aid  count_click  count_cart  count_order\n",
       "0     11098528            1          1            1           0            0\n",
       "1     11098529            1          1            1           0            0\n",
       "2     11098530            6          2            5           1            0\n",
       "3     11098531           24         11           20           0            4\n",
       "4     11098532            2          2            2           0            0\n",
       "...        ...          ...        ...          ...         ...          ...\n",
       "9995  11108528           40         32           34           6            0\n",
       "9996  11108529            5          3            5           0            0\n",
       "9997  11108530            8          5            8           0            0\n",
       "9998  11108531            2          2            2           0            0\n",
       "9999  11108532            1          1            1           0            0\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_session_aggregates(input_df):\n",
    "    session_feature = input_df.groupby([\"session\"]).agg({\"session\": \"count\", \"aid\": \"nunique\"})\n",
    "    session_feature.columns = [\"count_event\", \"count_aid\"]\n",
    "    # count events each type\n",
    "    for i, name in enumerate([\"click\", \"cart\", \"order\"]):\n",
    "        tmp = input_df.loc[input_df[\"type\"] == i].groupby([\"session\"]).agg({\"session\": \"count\"})\n",
    "        tmp.columns = [f\"count_{name}\"]\n",
    "        \n",
    "        session_feature = cudf.concat([session_feature, tmp], axis=1)\n",
    "        \n",
    "        del tmp\n",
    "        gc.collect()\n",
    "\n",
    "    return session_feature.fillna(0).reset_index()\n",
    "\n",
    "\n",
    "session_feature = get_session_aggregates(test_df)\n",
    "session_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c27ec4-da1d-48b0-8610-9a533abcffe4",
   "metadata": {},
   "source": [
    "### create train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bbcfb70-1c2c-4d6b-9b98-f5a9fdefaeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>count</th>\n",
       "      <th>count_event</th>\n",
       "      <th>count_aid</th>\n",
       "      <th>count_click</th>\n",
       "      <th>count_cart</th>\n",
       "      <th>count_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11099107</td>\n",
       "      <td>125597</td>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11099107</td>\n",
       "      <td>440855</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11099107</td>\n",
       "      <td>533638</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11099107</td>\n",
       "      <td>362150</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11099107</td>\n",
       "      <td>1645990</td>\n",
       "      <td>1858</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11108387</td>\n",
       "      <td>736002</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>11108387</td>\n",
       "      <td>341579</td>\n",
       "      <td>225</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11108387</td>\n",
       "      <td>1231891</td>\n",
       "      <td>655</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>11108387</td>\n",
       "      <td>795782</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11108387</td>\n",
       "      <td>203774</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session      aid  count  count_event  count_aid  count_click  \\\n",
       "0       11099107   125597    637            1          1            1   \n",
       "1       11099107   440855    290            1          1            1   \n",
       "2       11099107   533638    110            1          1            1   \n",
       "3       11099107   362150    220            1          1            1   \n",
       "4       11099107  1645990   1858            1          1            1   \n",
       "...          ...      ...    ...          ...        ...          ...   \n",
       "199995  11108387   736002     40           17         12           17   \n",
       "199996  11108387   341579    225           17         12           17   \n",
       "199997  11108387  1231891    655           17         12           17   \n",
       "199998  11108387   795782     65           17         12           17   \n",
       "199999  11108387   203774     37           17         12           17   \n",
       "\n",
       "        count_cart  count_order  \n",
       "0               -1           -1  \n",
       "1               -1           -1  \n",
       "2               -1           -1  \n",
       "3               -1           -1  \n",
       "4               -1           -1  \n",
       "...            ...          ...  \n",
       "199995          -1           -1  \n",
       "199996          -1           -1  \n",
       "199997          -1           -1  \n",
       "199998          -1           -1  \n",
       "199999          -1           -1  \n",
       "\n",
       "[200000 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_candidate_df = candidate_df.merge(item_feature, on=\"aid\", how=\"left\").astype(\"int32\").fillna(-1)\n",
    "new_candidate_df = new_candidate_df.merge(session_feature, on=\"session\", how=\"left\").astype(\"int32\").fillna(-1)\n",
    "new_candidate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc499fb-23ee-4a33-a608-0dbfba375b16",
   "metadata": {},
   "source": [
    "### add target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ba3eda-3d47-44e0-b436-5c47d9bd69d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>cart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1199737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098533</td>\n",
       "      <td>108676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098533</td>\n",
       "      <td>1406660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098533</td>\n",
       "      <td>988295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098533</td>\n",
       "      <td>1118792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569692</th>\n",
       "      <td>12899732</td>\n",
       "      <td>1126169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569693</th>\n",
       "      <td>12899739</td>\n",
       "      <td>301163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569694</th>\n",
       "      <td>12899739</td>\n",
       "      <td>1379999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569695</th>\n",
       "      <td>12899757</td>\n",
       "      <td>1677695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569696</th>\n",
       "      <td>12899766</td>\n",
       "      <td>573530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569697 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session      aid  cart\n",
       "0       11098528  1199737     1\n",
       "1       11098533   108676     1\n",
       "2       11098533  1406660     1\n",
       "3       11098533   988295     1\n",
       "4       11098533  1118792     1\n",
       "...          ...      ...   ...\n",
       "569692  12899732  1126169     1\n",
       "569693  12899739   301163     1\n",
       "569694  12899739  1379999     1\n",
       "569695  12899757  1677695     1\n",
       "569696  12899766   573530     1\n",
       "\n",
       "[569697 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = cudf.read_parquet(Config.INPUT_DIR / \"test_labels.parquet\")\n",
    "target = target.loc[target[\"type\"] == \"carts\"]\n",
    "target = target.explode(column=\"ground_truth\").drop(columns=[\"type\"]).astype(\"int32\").reset_index(drop=True)\n",
    "target.columns = [\"session\", \"aid\"]\n",
    "target[\"cart\"] = 1\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12eb7e36-abbe-40ff-b25f-1700769692d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>count</th>\n",
       "      <th>count_event</th>\n",
       "      <th>count_aid</th>\n",
       "      <th>count_click</th>\n",
       "      <th>count_cart</th>\n",
       "      <th>count_order</th>\n",
       "      <th>cart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098992</td>\n",
       "      <td>41302</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098992</td>\n",
       "      <td>706006</td>\n",
       "      <td>77</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098992</td>\n",
       "      <td>728827</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098992</td>\n",
       "      <td>64104</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098992</td>\n",
       "      <td>1010861</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11108502</td>\n",
       "      <td>1845463</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>11108502</td>\n",
       "      <td>1112740</td>\n",
       "      <td>387</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11108501</td>\n",
       "      <td>573604</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>11108502</td>\n",
       "      <td>1650562</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11108502</td>\n",
       "      <td>805848</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session      aid  count  count_event  count_aid  count_click  \\\n",
       "0       11098992    41302     78            8          6            7   \n",
       "1       11098992   706006     77            8          6            7   \n",
       "2       11098992   728827    149            8          6            7   \n",
       "3       11098992    64104    242            8          6            7   \n",
       "4       11098992  1010861     43            8          6            7   \n",
       "...          ...      ...    ...          ...        ...          ...   \n",
       "199995  11108502  1845463    219            2          2            2   \n",
       "199996  11108502  1112740    387            2          2            2   \n",
       "199997  11108501   573604     56            1          1            1   \n",
       "199998  11108502  1650562    165            2          2            2   \n",
       "199999  11108502   805848    370            2          2            2   \n",
       "\n",
       "        count_cart  count_order  cart  \n",
       "0                1           -1     0  \n",
       "1                1           -1     0  \n",
       "2                1           -1     0  \n",
       "3                1           -1     0  \n",
       "4                1           -1     0  \n",
       "...            ...          ...   ...  \n",
       "199995          -1           -1     0  \n",
       "199996          -1           -1     0  \n",
       "199997          -1           -1     0  \n",
       "199998          -1           -1     0  \n",
       "199999          -1           -1     0  \n",
       "\n",
       "[200000 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_candidate_df = new_candidate_df.merge(target, on=[\"session\", \"aid\"], how=\"left\").fillna(0)\n",
    "new_candidate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b750307-a3a4-49f1-a811-5da8cd92c223",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acc5d556-f742-44d5-9201-df56034c5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-map:0.94065\tvalid-map:0.93144\n",
      "[100]\ttrain-map:0.96386\tvalid-map:0.91589\n",
      "[200]\ttrain-map:0.97261\tvalid-map:0.91390\n",
      "[300]\ttrain-map:0.97771\tvalid-map:0.91248\n",
      "[400]\ttrain-map:0.97989\tvalid-map:0.91271\n",
      "[500]\ttrain-map:0.98203\tvalid-map:0.91241\n",
      "[600]\ttrain-map:0.98263\tvalid-map:0.91198\n",
      "[700]\ttrain-map:0.98290\tvalid-map:0.91170\n",
      "[800]\ttrain-map:0.98307\tvalid-map:0.91248\n",
      "[900]\ttrain-map:0.98343\tvalid-map:0.91208\n",
      "[999]\ttrain-map:0.98346\tvalid-map:0.91221\n",
      "[0]\ttrain-map:0.94466\tvalid-map:0.93761\n",
      "[100]\ttrain-map:0.96253\tvalid-map:0.91775\n",
      "[200]\ttrain-map:0.97291\tvalid-map:0.91640\n",
      "[300]\ttrain-map:0.97788\tvalid-map:0.91390\n",
      "[400]\ttrain-map:0.98038\tvalid-map:0.91400\n",
      "[500]\ttrain-map:0.98208\tvalid-map:0.91408\n",
      "[600]\ttrain-map:0.98321\tvalid-map:0.91330\n",
      "[700]\ttrain-map:0.98398\tvalid-map:0.91361\n",
      "[800]\ttrain-map:0.98434\tvalid-map:0.91381\n",
      "[900]\ttrain-map:0.98482\tvalid-map:0.91367\n",
      "[999]\ttrain-map:0.98523\tvalid-map:0.91368\n",
      "[0]\ttrain-map:0.93966\tvalid-map:0.92431\n",
      "[100]\ttrain-map:0.96565\tvalid-map:0.91193\n",
      "[200]\ttrain-map:0.97397\tvalid-map:0.91069\n",
      "[300]\ttrain-map:0.97826\tvalid-map:0.91099\n",
      "[400]\ttrain-map:0.98133\tvalid-map:0.91055\n",
      "[500]\ttrain-map:0.98240\tvalid-map:0.90998\n",
      "[600]\ttrain-map:0.98299\tvalid-map:0.90923\n",
      "[700]\ttrain-map:0.98376\tvalid-map:0.90870\n",
      "[800]\ttrain-map:0.98464\tvalid-map:0.90885\n",
      "[900]\ttrain-map:0.98440\tvalid-map:0.90822\n",
      "[999]\ttrain-map:0.98459\tvalid-map:0.90928\n",
      "[0]\ttrain-map:0.94290\tvalid-map:0.93778\n",
      "[100]\ttrain-map:0.96227\tvalid-map:0.92196\n",
      "[200]\ttrain-map:0.97237\tvalid-map:0.92006\n",
      "[300]\ttrain-map:0.97715\tvalid-map:0.92054\n",
      "[400]\ttrain-map:0.97968\tvalid-map:0.92044\n",
      "[500]\ttrain-map:0.98070\tvalid-map:0.92026\n",
      "[600]\ttrain-map:0.98145\tvalid-map:0.91923\n",
      "[700]\ttrain-map:0.98171\tvalid-map:0.91966\n",
      "[800]\ttrain-map:0.98209\tvalid-map:0.91924\n",
      "[900]\ttrain-map:0.98243\tvalid-map:0.91977\n",
      "[999]\ttrain-map:0.98260\tvalid-map:0.91990\n",
      "[0]\ttrain-map:0.94100\tvalid-map:0.94129\n",
      "[100]\ttrain-map:0.96218\tvalid-map:0.92533\n",
      "[200]\ttrain-map:0.97191\tvalid-map:0.92361\n",
      "[300]\ttrain-map:0.97643\tvalid-map:0.92296\n",
      "[400]\ttrain-map:0.97872\tvalid-map:0.92302\n",
      "[500]\ttrain-map:0.98061\tvalid-map:0.92266\n",
      "[600]\ttrain-map:0.98202\tvalid-map:0.92258\n",
      "[700]\ttrain-map:0.98241\tvalid-map:0.92164\n",
      "[800]\ttrain-map:0.98290\tvalid-map:0.92202\n",
      "[900]\ttrain-map:0.98335\tvalid-map:0.92263\n",
      "[999]\ttrain-map:0.98356\tvalid-map:0.92292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cpu: 7.0GB(+0.0GB), gpu: 1.3GB(+0.0GB): 21.7sec] training \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold\n",
    "\n",
    "feature_cols = ['count', 'count_event', 'count_aid', 'count_click', 'count_cart', 'count_order']\n",
    "\n",
    "with trace.timer(\"training\"):\n",
    "    cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(new_candidate_df.to_numpy(), new_candidate_df[\"cart\"].to_numpy(), groups=new_candidate_df[\"session\"].to_numpy())):\n",
    "        X_train = new_candidate_df.loc[train_idx, feature_cols]\n",
    "        y_train = new_candidate_df.loc[train_idx, \"cart\"]\n",
    "        X_valid = new_candidate_df.loc[valid_idx, feature_cols]\n",
    "        y_valid = new_candidate_df.loc[valid_idx, \"cart\"]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, y_train, group=[20] * (len(train_idx) // 20))\n",
    "        dvalid = xgb.DMatrix(X_valid, y_valid, group=[20] * (len(valid_idx) // 20))\n",
    "\n",
    "        xgb_parms = {'objective':'rank:pairwise', 'tree_method':'gpu_hist'}\n",
    "        model = xgb.train(\n",
    "            xgb_parms, \n",
    "            dtrain=dtrain,\n",
    "            evals=[(dtrain,'train'), (dvalid,'valid')],\n",
    "            num_boost_round=1000,\n",
    "            verbose_eval=100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605ddd7-afd1-449d-b05c-dce4fcf446b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de360c3a-10f7-4f9a-8e02-a9a6e3f7592e",
   "metadata": {},
   "source": [
    "### validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678d5fa-8e1a-4c5c-8d41-e7b3cf84a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"make pred_df\"):\n",
    "    pred_clicks_df = pd.DataFrame(pred_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "    pred_carts_df = pd.DataFrame(pred_carts.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()\n",
    "    pred_orders_df = pd.DataFrame(pred_orders.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "    pred_df = pd.concat([pred_clicks_df, pred_carts_df, pred_orders_df], axis=0).reset_index(drop=True)\n",
    "    pred_df.columns = [\"session_type\", \"labels\"]\n",
    "    pred_df[\"labels\"] = pred_df[\"labels\"].apply(lambda x: \" \".join(map(str, x)))\n",
    "    pred_df.to_csv(\n",
    "        Config.OUTPUT_DIR / f\"exp{Config.EXP_ID}_validation.csv\" if Config.VALIDATION else Config.OUTPUT_DIR / f\"exp{Config.EXP_ID}_sub.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6ac19-4336-4cb6-9db8-3f2e74f51327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with trace.timer(\"delete temp file\"):\n",
    "    del test_df\n",
    "    del top_15_carts2orders, top_15_buy2buy, top_20_clicks, top_clicks, top_carts, top_orders\n",
    "    del pred_clicks, pred_buys\n",
    "    del pred_clicks_df, pred_carts_df, pred_orders_df\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596a73d-fe5f-4fe7-921c-1800d2ab82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace.timer(\"compute cv score\"):\n",
    "    # COMPUTE METRIC\n",
    "    score = 0\n",
    "    weights = {'clicks': 0.10, 'carts': 0.30, 'orders': 0.60}\n",
    "    for t in ['clicks','carts','orders']:\n",
    "        sub = pred_df.loc[pred_df.session_type.str.contains(t)].copy()\n",
    "        sub['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "        sub.labels = sub.labels.apply(lambda x: [int(i) for i in x.split(' ')[:20]])\n",
    "        test_labels = pd.read_parquet(Config.INPUT_DIR / \"test_labels.parquet\")\n",
    "        test_labels = test_labels.loc[test_labels['type']==t]\n",
    "        test_labels = test_labels.merge(sub, how='left', on=['session'])\n",
    "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "        recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "        score += weights[t]*recall\n",
    "        print(f'{t} recall =',recall)\n",
    "\n",
    "    print('=============')\n",
    "    print('Overall Recall =',score)\n",
    "    print('=============')\n",
    "    \n",
    "    del sub, test_labels, recall, score\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb40280-94dd-4b73-8f94-208b59119237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
